<html>
<head>
	<title>GenLin</title>
	<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
	<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
	  MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "AMS"} } });
	</script>
	<script type="text/javascript"
	  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>
	<style>
		body{
			font-family: 'Open Sans', sans-serif;
			margin:10%;
			font-size: 20px;
		}
		a{
			color: #333333;
			text-decoration: none;
		}
		a:hover{
			color: #aaaaaa;
		}
	</style>
</head>
<body>
<h1>Generalized Linear Models</h1>
<hr>
<h2>Content</h2>
<ol>
	<li><a href="#efam">Exponential Familiy</a>
		<ol>
			<li><a href="#edfa">Exponential Disperson Family</a></li>
			<li><a href="#jorg">J&#248;rgensen's Exponential Disperson Family Model</a></li>
			<li><a href="#mlee">Maximum Likelihood Estimates</a></li>
		</ol></li>
	<li><a href="#logm">Logistic Model</a></li>
	<li><a href="#prom">Probit Model</a></li>
	<li><a href="#poim">Poission Model</a></li>
</ol>
<hr>
<a name="efam"></a><h2>Exponential Familiy</h2>
Consider $Y_i$ with distribution belonging to the linear exponential family (EF), 
\begin{equation}
	f_{Y_i}(Y_i|\theta) = \exp(-b(\theta)+ \theta y_i + c(y_i))
\end{equation}
where $b(\theta)$ is a function of the parameters only and $c(y_i)$ is a function of the data only.
Assuming that the first 2 partial derivatives exist for all $\theta$ in the define support of the paprameter space, let
\begin{align*}
	&I(\theta;y_i) = \log(f_{Y_i}(Y_i|\theta))\\
	&\dot{I}(\theta;y_i) = \frac{\partial I(\theta;y_i)}{\partial\theta}\\
	&\ddot{I}(\theta;y_i) = \frac{\partial^2 I(\theta;y_i)}{\partial\theta^2}
\end{align*}
In particular 
\begin{equation}
	\label{eq:efexpand}
	\dot{I}(\theta;y_i) = \frac{\partial}{\partial \theta} (-b(\theta)+ \theta y_i + c(y_i)) = -\dot{b}(\theta) + y_i
\end{equation}
and 
\begin{equation}
	\label{eq:efexpandd}
	\ddot{I}(\theta;y_i) = \frac{\partial}{\partial \theta}(-\dot{b}(\theta) + y_i) = -\ddot{b}(\theta)
\end{equation}
Here are some interesting properties.
<ol><li>
\begin{equation}
  \label{eq:efexp}
  E\left[\dot{I}(\theta;y_i)\right] = 0
\end{equation}
</li><li>
	Let $E\left[m(y_i, \theta)\right] = 0$ for some function $m$, then 
\begin{equation}
	E\left[\frac{\partial m(y_i, \theta)}{\partial \theta'}\right] = 
	-E\left[m(y_i, \theta)\frac{\partial I(\theta;y_i)}{\partial\theta'}\right]
\end{equation}
</li><li>
	In the special case when $m(y_i, \theta) = \dot{I}(\theta;y_i)$,
	\begin{equation}
	\label{eq:efvar}
	E\left[\ddot{I}(\theta;y_i)\right] = 
	-E\left[(\dot{I}(\theta;y_i))^2\right]
\end{equation} 
</li>
</ol>
<!-- TODO: PROOFS -->
Using these result, we can get the followings
<h4>Expectation</h4>
Combining equation \eqref{eq:efexpand} and \eqref{eq:efexp}, 
\begin{align*}
	E\left[\dot{I}(\theta;y_i)\right] = E[-\dot{b}(\theta) + y_i] = -\dot{b}(\theta) + E[y_i] = 0
\end{align*}
Therefore, 
\begin{equation}
\dot{b}(\theta) = E[y_i]
\end{equation}
<h4>Varaince</h4>
Combining equation \eqref{eq:efexpandd} and \eqref{eq:efvar}, 
\begin{align*}
	-E\left[\ddot{I}(\theta;y_i)\right] = E\left[(\dot{I}(\theta;y_i))^2\right] = E[(-\dot{b}(\theta) + y_i)^2] = Var(y_i)
\end{align*}
Hence, 
\begin{equation}
\ddot{b}(\theta) = Var(y_i)
\end{equation}
Seeing that $b(\theta)$ can get the moments of $Y_i$, this function is thus given the name cumulent function. 
<a name="edfa"></a><h3>Exponential Disperson Family</h3>
Consider $Y_i$ with distribution belonging to the linear exponential dispersion family (EDF), 
\begin{equation}
	f_{Y_i}(Y_i|\theta, \phi) = \exp\left(\frac{\theta y_i-b(\theta)}{a(\phi)} + c(y_i, \phi)\right)
\end{equation}
where $\phi$ modifies the disperson in a multiplicative way. In this case, the expectation and variance of $Y_i$ are respectively
\begin{align*}
&E[Y_i] = \dot{b}(\theta)\\
&Var[Y_i] = \ddot{b}(\theta)a(\phi)
\end{align*}
<a name="jorg"></a><h3>J&#248;rgensen's Exponential Disperson Family Model</h3>
J&#248;rgensen showed that there do not exist many discrete distribution which can be expressed as the continuous exponential dispersion family ditribution. So he proposed 
\begin{equation}
	f_{Y_i}(Y_i|\theta, \phi) = \exp\left(\theta y_i-\frac{b(\theta)}{a(\phi)} + c(y_i, \phi)\right)
\end{equation}
wich expectation and variance 
\begin{align*}
&E[Y_i] = \dot{b}(\theta)/a(\phi)\\
&Var[Y_i] = \ddot{b}(\theta)a(\phi)
\end{align*}
<a href="mlee"></a><h3>Maximum Likelihood Estimates</h3>
<hr>
<a name="logm"></a><h2>Probit Model</h2>

<hr>
<a name="prom"></a><h2>Logistic Model</h2>
<hr>
<a name="poim"></a><h2>Poission Model</h2>
<hr>
MATH 523 Generalized Linear Models, by Russell Steele<br>
McGill University, Winter 2015<br>
</body>
</html>